{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8zZk8VJ1P3_"
      },
      "outputs": [],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4vM3ocrWgmbn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "import optuna\n",
        "from optuna.trial import TrialState\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3mjLoFHksbk"
      },
      "source": [
        "# Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KpCRjWaEzlWL"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "df = pd.read_csv(\"erdos_renyi_a-g_with_graph_features.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNj1GB6jzlWL"
      },
      "outputs": [],
      "source": [
        "# Set list of predictors\n",
        "predictors = ['p', 'Number of vertices', 'Number of edges', 'Edge density',\n",
        "       'Mean degree', 'Standard deviation of degrees', 'Skewness of degrees',\n",
        "       'Minimum degree', 'Maximum degree', 'Diameter', 'Radius',\n",
        "       'Vertex connectivity', 'Edge connectivity',\n",
        "       'Global clustering coefficient', 'Mean local clustering coefficient',\n",
        "       'Standard deviation of local clustering coefficients',\n",
        "       'Skewness of local clustering coefficients',\n",
        "       'Minimum local clustering coefficient',\n",
        "       'Maximum local clustering coefficient', 'Treewidth',\n",
        "       'Average path length', 'Circuit rank', 'Girth',\n",
        "       'Mean betweenness centrality',\n",
        "       'Standard deviation of betweenness centralities',\n",
        "       'Skewness of betweenness centralities',\n",
        "       'Minimum betweenness centrality', 'Maximum betweenness centrality',\n",
        "       'Algebraic connectivity', 'Von Neumann entropy',\n",
        "       'Adjacency spectrum mean', 'Adjacency spectrum standard deviation',\n",
        "       'Adjacency spectrum skewness', 'Adjacency spectrum min',\n",
        "       'Adjacency spectrum max', 'Laplacian spectrum mean',\n",
        "       'Laplacian spectrum standard deviation', 'Laplacian spectrum skewness',\n",
        "       'Laplacian spectrum min', 'Laplacian spectrum max', 'Planarity',\n",
        "       'Mean harmonic centrality',\n",
        "       'Standard deviation of harmonic centralities',\n",
        "       'Skewness of harmonic centralities', 'Minimum harmonic centrality',\n",
        "       'Maximum harmonic centrality', 'Harmonic diameter', 'Mean core number',\n",
        "       'Standard deviation of core numbers', 'Skewness of core numbers',\n",
        "       'Minimum core number', 'Maximum core number', 'Chordality',\n",
        "       'Haemers bound', 'Claw-free']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QhZsnFgnzlWM"
      },
      "outputs": [],
      "source": [
        "# Split df into training & testing dataset (ratio of 80:20)\n",
        "df_y = df['f_calls']\n",
        "df_x = df[predictors]\n",
        "train_x, test_x, train_y, test_y = train_test_split(df_x, df_y, test_size=.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzPWD_t4zlWM"
      },
      "outputs": [],
      "source": [
        "# Construct tensors for training & testing datasets\n",
        "train_X = torch.tensor(train_x.to_numpy(), dtype=torch.float32)\n",
        "train_Y = torch.tensor(train_y.to_numpy(), dtype=torch.float32).reshape(-1, 1)\n",
        "test_X = torch.tensor(test_x.to_numpy(), dtype=torch.float32)\n",
        "test_Y = torch.tensor(test_y.to_numpy(), dtype=torch.float32).reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMlFlCmp2cgF"
      },
      "source": [
        "# Optuna Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "njt4m5Y22d91"
      },
      "outputs": [],
      "source": [
        "DEVICE = torch.device(\"cpu\")\n",
        "EPOCHS = 1500\n",
        "\n",
        "# We optimize the number of layers & hidden units\n",
        "def define_model(trial):\n",
        "    n_layers = trial.suggest_int(\"n_layers\", 1, 5)\n",
        "    layers = []\n",
        "\n",
        "    # Set input & output dimensions\n",
        "    in_features = len(predictors)\n",
        "    output_size = 1\n",
        "\n",
        "    for i in range(n_layers):\n",
        "        out_features = trial.suggest_int(\"n_units_l{}\".format(i), 4, 128)\n",
        "        layers.append(nn.Linear(in_features, out_features))\n",
        "        layers.append(nn.ReLU())\n",
        "\n",
        "        in_features = out_features\n",
        "\n",
        "    layers.append(nn.Linear(in_features, output_size))\n",
        "    layers.append(nn.ReLU())\n",
        "\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "# We optimize the optimizer type & learning rate\n",
        "def objective(trial):\n",
        "    # Generate model\n",
        "    model = define_model(trial).to(DEVICE)\n",
        "\n",
        "    # Generate the optimizers\n",
        "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
        "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
        "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
        "\n",
        "    # Construct tensors for training & testing datasets\n",
        "    train_X = torch.tensor(train_x.to_numpy(), dtype=torch.float32)\n",
        "    train_Y = torch.tensor(train_y.to_numpy(), dtype=torch.float32).reshape(-1, 1)\n",
        "    test_X = torch.tensor(test_x.to_numpy(), dtype=torch.float32)\n",
        "    test_Y = torch.tensor(test_y.to_numpy(), dtype=torch.float32).reshape(-1, 1)\n",
        "\n",
        "    # Model training\n",
        "    for epoch in range(EPOCHS):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        output = model(train_X)\n",
        "        loss = F.mse_loss(output, train_Y)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        # Model validation\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            output = model(test_X)\n",
        "\n",
        "        r_2 = r2_score(np.array(test_Y.detach().numpy()), output.detach().numpy())\n",
        "\n",
        "        trial.report(r_2, epoch)\n",
        "\n",
        "        # Handle pruning based on the intermediate value.\n",
        "        if trial.should_prune():\n",
        "            raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "    return r_2\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    study = optuna.create_study(direction=\"maximize\")\n",
        "    study.optimize(objective, n_trials=100, timeout=600)\n",
        "\n",
        "    pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
        "    complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
        "\n",
        "    print(\"Study statistics: \")\n",
        "    print(\"  Number of finished trials: \", len(study.trials))\n",
        "    print(\"  Number of pruned trials: \", len(pruned_trials))\n",
        "    print(\"  Number of complete trials: \", len(complete_trials))\n",
        "\n",
        "    print(\"Best trial:\")\n",
        "    trial = study.best_trial\n",
        "\n",
        "    print(\"  Value: \", trial.value)\n",
        "\n",
        "    print(\"  Params: \")\n",
        "    for key, value in trial.params.items():\n",
        "        print(\"    {}: {}\".format(key, value))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}